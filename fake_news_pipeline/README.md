    # Fake News Pipeline

    Ovaj projekat implementira ETL pipeline i pripremu podataka za detekciju laÅ¾nih vesti.  
    Cilj je prikupiti nove vesti, spojiti ih sa Kaggle dataset-om i pripremiti CSV za trening ML modela.

    Ovaj projekat implementira automatizovani pipeline za:
        - ğŸ“° Prikupljanje novih vesti (web scraping)
        - ğŸ—„ï¸ ETL proces i skladiÅ¡tenje u PostgreSQL bazu
        - ğŸ”„ Spajanje sa originalnim Kaggle dataset-om
        - ğŸ§  Re-treniranje ML modela na proÅ¡irenom dataset-u
        - ğŸ¯ **Cilj:** ReÅ¡avanje temporal domain shift problema iz glavnog projekta

    ## Struktura projekta
    fake_news_pipeline/
    â”‚
    â”œâ”€â”€ app/
    â”‚ â”œâ”€â”€ scraper/ # skripte za scraping novonabavljenih vesti
    â”‚ â”œâ”€â”€ etl/ # ETL skripte za ÄiÅ¡Ä‡enje i pripremu podataka
    â”‚ â”œâ”€â”€ training/ # skripte za re-trening modela
    â”‚ â””â”€â”€ config/ # konfiguracija i konekcija ka Postgres
    â”‚
    â”œâ”€â”€ database/ # Docker volume za Postgres
    â”œâ”€â”€ data/ # CSV fajlovi: Fake.csv, True.csv, fake_news_latest.csv
    â”œâ”€â”€ models/ # saÄuvani modeli i TF-IDF vektorizatori
    â”œâ”€â”€ tests/ # testovi (opciono)
    â”‚
    â”œâ”€â”€ docker-compose.yml # Postgres container
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ .env
    â””â”€â”€ README.md

    ---

    ## Tehnologije i biblioteke

    - Python 3.11  
    - Pandas  
    - SQLAlchemy  
    - psycopg2  
    - scikit-learn  
    - Docker / Docker Compose  

    ---

    ## Instalacija i pokretanje

    1. Kloniraj repozitorijum:

    ```bash
    git clone <repo-link>
    Pokreni virtualno okruÅ¾enje i instaliraj zavisnosti:

    python -m venv venv
    source venv/bin/activate   # Linux/Mac
    .\venv\Scripts\activate    # Windows
    pip install -r requirements.txt


    Pokreni Docker container za Postgres:

    docker compose up -d


    Pokreni scraper (ako Å¾eliÅ¡ nove vesti):

    python -m app.scraper.scraper


    Ubaci Kaggle dataset u Postgres:

    python -m app.etl.load_csv_to_postgres


    Napravi finalni CSV za trening:

    python -m app.etl.create_training_csv


    Re-treniraj ML model:

    python -m app.training.train_model

    Tabele u bazi
    Tabela	SadrÅ¾aj	Label
    fake_news	Kaggle FAKE vesti	1
    true_news	Kaggle TRUE vesti	0
    news	Novonabavljene vesti preko scraping-a	0

    ## Predikcija novih vesti 
    import joblib

    model = joblib.load("models/fake_news_model_updated.pkl")
    vectorizer = joblib.load("models/tfidf_vectorizer.pkl")

    texts = ["Primer laÅ¾ne vesti", "Primer prave vesti"]
    pred = model.predict(vectorizer.transform(texts))

    print(pred)  # 0 = TRUE, 1 = FAKE
    Napomene
    - Originalni model u folderu Fake_news_detection ostaje netaknut.

    - Novi model (fake_news_model_updated.pkl) se koristi samo za nove podatke.

    - Scraping novih vesti moÅ¾e biti unapreÄ‘en i automatizovan periodiÄki.

    Autor
    Darko Matic